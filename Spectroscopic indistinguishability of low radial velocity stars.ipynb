{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectroscopic indistinguishability of low frequency seperated red giant branch stars\n",
    "Current models are able to cleanly separate red giant branch stars from red clump stars with a great accuracy rate. Unfortunately, much of this accuracy is overstated as the core problem of overlap between red clump stars and red giant branch stars still has a sizable amount of contamination. This area of overlap is around $log(g) \\approx 2.5$ as RGB stars mature and climb the red giant branch. Here, metal poor RGB stars and higher mass stars that burn hotter and edge closer to the red clump contaminate attempts of characterizing red clump stars in the $T_{eff}-log(g)$ space. Notable stars that contaminate red clumps are RGB stars of low frequency separation and hot RGB stars. Essentially, all models (linear  and non-linear) to learn a better separation have failed, for a few reasons:\n",
    "\n",
    "1. The period spacing for RGB stars of low frequency separated RGB stars is difficult\n",
    "> However, we should keep in mind that at low ∆ν (i.e. a high luminosity on the RGB), when gravity-dominated mixed\n",
    "modes have high inertias, detecting ∆Π1 becomes challenging.\n",
    "Source: https://arxiv.org/pdf/1512.03656.pdf\n",
    "\n",
    "2. Low frequency separated RGB stars (high luminosity) tend to burn hotter since luminosity is correlated with temperature\n",
    "\n",
    "3. In the Vrad sample, there are few RGB stars in this \"fuzzy\" zone, making it difficult to train a model due to the inherent problem of lack of data\n",
    "\n",
    "We show that these problems also show up when we attempt to use stellar spectra to discriminate red clump and red giant branch stars. While we are able to achieve better than current model accuracy, this metric is disputable for a few reasons, the main being that since there are so few stars in said \"fuzzy\" region, the error is very discrete so most of it might be attributable to noise. What we hope to achieve is a model that we intuitively think is very generalizable and shows good performance on this \"fuzzy\" region with the fewest number of training examples. If it generalizes well on our narrow strip of data despite having seen very few examples, then this is good intuitive evidence that it will generalize outside. We show that random forests have this desirable property while neural networks, having a very good training accuracy, show poor generalization. \n",
    "\n",
    "It is also noted that virtually all misclassified red giant branch stars have high surface gravity and are quite hot with low frequency seperation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What a red clump and a red giant branch star look like\n",
    "The average red giant branch spectra and red clump spectra differ in spectra-space by a noticeable average l2 norm. When they are dimensionally reduced using PCA, the loss of information is almost negligible where the average l2 norm difference is off by $ < 0.00015\\%$\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\begin{aligned}\\text{Average RGB - Average RC} &= 0.29601430892944336\\\\\\text{Average reconstructed RGB - Average reconstructed RC} &= 0.29601430892944336\\end{aligned}\\end{equation}$$\n",
    "![title](plots/spectra/fig1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low frequency separated red giant branch stars in regression space "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, one of the best models I was able to create (a very small shallow 2 hidden layer neural network on 100 principal components from spectra) performs a regression task of predicting the large frequency seperation and period spacing of a star from stellar spectra. For the most part, it performs quite well in large frequency seperation axis with a mean error of $ < 0.3$. However, in period spacing, we have a mean absolute error of $\\approx 23$, and with hand tuning of models, we can get this down to about $20$, which is a very small improvement. Plotted below are stars colored by ground truth from Kepler asteroseismic data and their respective locations in $\\Delta{}v-PS$ space, the left being what the regression model predicted and the right being the ground truth. As we see, low frequency seperated red giant branch stars significantly contaminate the red clump samples at $4.5 \\leq \\Delta{}v \\leq 7$\n",
    "\n",
    "![title](plots/spectra/fig3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification errors in $\\Delta{}v-\\Pi_1$ space\n",
    "Here, we show a model, (shallow neural network on 100 principal components from stellar spectra) performance on a classification task. We plot the classification errors in $\\Delta{}v-PS$ space, the left is the regression model's predicted values and the right is the ground truth. We clearly see that there is a clear connection between the RGB and RC stars that are misclassified and their respective regression errors, showing that there is some connection between the regression error and classification error. We also observe that all the classification errors are in the area of low frequency separated RGB stars, the same area that is known to be difficult to observe period spacing\n",
    "\n",
    "![title](plots/spectra/fig4.png)\n",
    "\n",
    "## Classification errors in $T_{eff}-log(g)$ space\n",
    "The same misclassied stars from above, but now in $T_{eff}-log(g)$ space. \n",
    "![title](plots/spectra/fig5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## What are difficult stars?\n",
    "\n",
    "What does a typical difficult star look like and why is it difficult? We examine the seemingly \"difficult\" red giant branch stars in spectroscopic space. Below is table of incorrectly classified stars that all models consistently get wrong after 8-fold cross validation, the models used were 2,000 neuron network, random forests, and logisitic regression\n",
    "\n",
    "### Misclassified RGB stars\n",
    "<table>\n",
    "<thead><tr><td>KIC</td><td>M</td><td>T_eff</td><td>log(g)</td><td>M_H</td><td>C</td><td>N</td><td>Fe</td><td>Dnu</td><td>PS</td></tr></thead>\n",
    "<tr><td>5112361</td><td>1.880</td><td>4843.621</td><td>2.564</td><td>0.072</td><td>0.130</td><td>0.712</td><td>0.060</td><td>6.180</td><td>85.400</td></tr>\n",
    "<tr><td>11605129</td><td>1.750</td><td>4827.256</td><td>2.502</td><td>0.049</td><td>-0.062</td><td>0.427</td><td>0.053</td><td>4.620</td><td>66.700</td></tr>\n",
    "<tr><td>10196240</td><td>1.450</td><td>4719.284</td><td>2.432</td><td>0.141</td><td>0.063</td><td>0.460</td><td>0.145</td><td>4.040</td><td>65.700</td></tr>\n",
    "<tr><td>5857618</td><td>2.130</td><td>4702.592</td><td>2.736</td><td>0.303</td><td>0.236</td><td>0.955</td><td>0.309</td><td>6.330</td><td>82.600</td></tr>\n",
    "<tr><td>3449907</td><td>1.460</td><td>4714.393</td><td>2.621</td><td>0.116</td><td>0.062</td><td>0.520</td><td>0.129</td><td>5.350</td><td>63.900</td></tr>\n",
    "<tr><td>8561202</td><td>1.770</td><td>4974.931</td><td>2.503</td><td>-0.348</td><td>-0.502</td><td>0.040</td><td>-0.350</td><td>5.820</td><td>69.600</td></tr>\n",
    "<tr><td>8891957</td><td>1.740</td><td>4847.681</td><td>2.506</td><td>-0.101</td><td>-0.110</td><td>0.131</td><td>-0.095</td><td>6.140</td><td>66.700</td></tr>\n",
    "<tr><td>2449558</td><td>1.920</td><td>4895.564</td><td>2.606</td><td>0.023</td><td>-0.086</td><td>0.400</td><td>0.009</td><td>7.610</td><td>74.600</td></tr>\n",
    "<tr><td>11620695</td><td>1.450</td><td>4773.983</td><td>2.525</td><td>-0.194</td><td>-0.299</td><td>0.090</td><td>-0.196</td><td>4.630</td><td>58.600</td></tr>\n",
    "<tr><td>8708536</td><td>2.820</td><td>4993.769</td><td>2.724</td><td>0.200</td><td>-0.013</td><td>0.675</td><td>0.195</td><td>7.920</td><td>73.900</td></tr>\n",
    "<tr><td>3220095</td><td>0.750</td><td>4875.869</td><td>2.387</td><td>-0.314</td><td>-0.235</td><td>-0.214</td><td>-0.335</td><td>3.930</td><td>49.700</td></tr>\n",
    "</table>\n",
    "\n",
    "### Misclassified RC stars\n",
    "<table>\n",
    "<thead><tr><td>KIC</td><td>M</td><td>T_eff</td><td>log(g)</td><td>M_H</td><td>C</td><td>N</td><td>Fe</td><td>Dnu</td><td>PS</td></tr></thead>\n",
    "<tr><td>5613570</td><td>1.500</td><td>4596.656</td><td>2.644</td><td>0.306</td><td>0.252</td><td>0.690</td><td>0.306</td><td>5.510</td><td>345.700</td></tr>\n",
    "<tr><td>10136291</td><td>1.160</td><td>4555.111</td><td>2.417</td><td>-0.185</td><td>-0.131</td><td>-0.001</td><td>-0.183</td><td>4.120</td><td>290.500</td></tr>\n",
    "</table>\n",
    "\n",
    "In order to present better evidence and analysis of what difficult stars the model is getting confused about, I run the classifier on the entire dataset of Kepler and ignore uncertainity on period spacing. This is because period spacing never crosses the decision boundary in $\\Delta{}v-\\Pi_1$ space as demonstrate below with the uncertainity error lines. As such, it is safe to rely on the `status` field provided by Kepler.\n",
    "![title](plots/spectra/fig8.png)\n",
    "\n",
    "In this case, we will only focus on misclassified RGB stars, in this case, they were these:\n",
    "\n",
    "### Misclassified RGB stars on lenient Kepler dataset\n",
    "<table>\n",
    "<thead><tr><td>KIC</td><td>M</td><td>T_eff</td><td>log(g)</td><td>M_H</td><td>C</td><td>N</td><td>Fe</td><td>Dnu</td><td>PS</td><td>$\\sigma(X)$</tr></thead>\n",
    "<tr><td>3220095</td><td>0.750</td><td>4875.869</td><td>2.387</td><td>-0.314</td><td>-0.235</td><td>-0.214</td><td>-0.335</td><td>3.930</td><td>49.700</td><td>0.994</td></tr>\n",
    "<tr><td>10196240</td><td>1.450</td><td>4719.284</td><td>2.432</td><td>0.141</td><td>0.063</td><td>0.460</td><td>0.145</td><td>4.040</td><td>65.700</td><td>0.993</td></tr>\n",
    "<tr><td>11605129</td><td>1.750</td><td>4827.256</td><td>2.502</td><td>0.049</td><td>-0.062</td><td>0.427</td><td>0.053</td><td>4.620</td><td>66.700</td><td>0.986</td></tr>\n",
    "<tr><td>8561202</td><td>1.770</td><td>4974.931</td><td>2.503</td><td>-0.348</td><td>-0.502</td><td>0.040</td><td>-0.350</td><td>5.820</td><td>69.600</td><td>0.978</td></tr>\n",
    "<tr><td>8708536</td><td>2.820</td><td>4993.769</td><td>2.724</td><td>0.200</td><td>-0.013</td><td>0.675</td><td>0.195</td><td>7.920</td><td>73.900</td><td>0.978</td></tr>\n",
    "<tr><td>5956977</td><td>1.650</td><td>4786.444</td><td>2.605</td><td>-0.345</td><td>-0.269</td><td>-0.071</td><td>-0.350</td><td>5.760</td><td>61.100</td><td>0.955</td></tr>\n",
    "<tr><td>11296211</td><td>1.220</td><td>4583.735</td><td>2.392</td><td>-0.436</td><td>-0.391</td><td>-0.358</td><td>-0.444</td><td>4.050</td><td>59.300</td><td>0.915</td></tr>\n",
    "<tr><td>9353950</td><td>1.330</td><td>4680.665</td><td>2.472</td><td>-0.302</td><td>-0.233</td><td>-0.149</td><td>-0.296</td><td>5.320</td><td>65.100</td><td>0.904</td></tr>\n",
    "<tr><td>8697068</td><td>1.330</td><td>4585.712</td><td>2.420</td><td>-0.242</td><td>-0.150</td><td>-0.045</td><td>-0.241</td><td>5.290</td><td>66.700</td><td>0.895</td></tr>\n",
    "<tr><td>3449907</td><td>1.460</td><td>4714.393</td><td>2.621</td><td>0.116</td><td>0.062</td><td>0.520</td><td>0.129</td><td>5.350</td><td>63.900</td><td>0.867</td></tr>\n",
    "<tr><td>8891957</td><td>1.740</td><td>4847.681</td><td>2.506</td><td>-0.101</td><td>-0.110</td><td>0.131</td><td>-0.095</td><td>6.140</td><td>66.700</td><td>0.864</td></tr>\n",
    "<tr><td>11620695</td><td>1.450</td><td>4773.983</td><td>2.525</td><td>-0.194</td><td>-0.299</td><td>0.090</td><td>-0.196</td><td>4.630</td><td>58.600</td><td>0.860</td></tr>\n",
    "<tr><td>8411792</td><td>1.190</td><td>4758.275</td><td>2.573</td><td>-0.643</td><td>-0.536</td><td>-0.700</td><td>-0.653</td><td>5.010</td><td>60.600</td><td>0.850</td></tr>\n",
    "<tr><td>6196374</td><td>1.180</td><td>4584.920</td><td>2.423</td><td>-0.204</td><td>-0.126</td><td>0.013</td><td>-0.196</td><td>4.850</td><td>58.200</td><td>0.816</td></tr>\n",
    "<tr><td>10903247</td><td>1.300</td><td>4717.447</td><td>2.510</td><td>-0.190</td><td>-0.247</td><td>0.056</td><td>-0.189</td><td>4.800</td><td>64.200</td><td>0.556</td></tr>\n",
    "<tr><td>9994845</td><td>1.470</td><td>4584.460</td><td>2.394</td><td>0.053</td><td>0.008</td><td>0.348</td><td>0.058</td><td>3.770</td><td>53.500</td><td>0.510</td></tr>\n",
    "</table>\n",
    "\n",
    "Misclassified RGB stars not only pose a problem in classification, but also in regression for their period spacing - a very determential factor in seperating RGB stars from RC stars. These problematic stars consistently arise in hot RGB stars with a $log(g) \\approx 2.5$ and low $\\Delta{}v$. Here we also show the uncertainity of low $\\Delta{}v$ stars in probability space assigned by the neural network classifier\n",
    "\n",
    "![title](plots/spectra/fig11.png)\n",
    "\n",
    "## How do highly misclassified RGB stars compare to each other?\n",
    "We see if there is some sort of correlation between these stars that are always misclassified, specifically those of higher than $0.85$ probability of being a RC, despite not being an RC. From the spectra graph, while there are similairites, it is not exactly clear (what I was really hoping for was understanding or finding a common pattern in these strongly misclassified RGB stars)\n",
    "\n",
    "![title](plots/spectra/fig14.png)\n",
    "\n",
    "\n",
    "## Misclassified RGB stars in spectral space\n",
    "\n",
    "\n",
    "## Misclassified red giant branch stars\n",
    "<table>\n",
    "<thead><tr><td>KIC</td><td>M</td><td>T_eff</td><td>log(g)</td><td>M_H</td><td>C</td><td>N</td><td>Fe</td><td>Dnu</td><td>PS</td><td>PS Reg.</td></tr></thead>\n",
    "<tr><td>2449558</td><td>1.92</td><td>4895.56</td><td>2.61</td><td>0.02</td><td>-0.09</td><td>0.40</td><td>0.01</td><td>7.61</td><td>74.60</td><td>182.28</td></tr>\n",
    "<tr><td>3220095</td><td>0.75</td><td>4875.87</td><td>2.39</td><td>-0.31</td><td>-0.24</td><td>-0.21</td><td>-0.33</td><td>3.93</td><td>49.70</td><td>294.69</td></tr>\n",
    "<tr><td>3449907</td><td>1.46</td><td>4714.39</td><td>2.62</td><td>0.12</td><td>0.06</td><td>0.52</td><td>0.13</td><td>5.35</td><td>63.90</td><td>243.14</td></tr>\n",
    "<tr><td>8561202</td><td>1.77</td><td>4974.93</td><td>2.50</td><td>-0.35</td><td>-0.50</td><td>0.04</td><td>-0.35</td><td>5.82</td><td>69.60</td><td>248.16</td></tr>\n",
    "<tr><td>8708536</td><td>2.82</td><td>4993.77</td><td>2.72</td><td>0.20</td><td>-0.01</td><td>0.68</td><td>0.20</td><td>7.92</td><td>73.90</td><td>244.79</td></tr>\n",
    "<tr><td>8891957</td><td>1.74</td><td>4847.68</td><td>2.51</td><td>-0.10</td><td>-0.11</td><td>0.13</td><td>-0.09</td><td>6.14</td><td>66.70</td><td>261.82</td></tr>\n",
    "<tr><td>10196240</td><td>1.45</td><td>4719.28</td><td>2.43</td><td>0.14</td><td>0.06</td><td>0.46</td><td>0.15</td><td>4.04</td><td>65.70</td><td>291.44</td></tr>\n",
    "<tr><td>11097749</td><td>1.56</td><td>4900.09</td><td>2.59</td><td>-0.06</td><td>-0.12</td><td>0.20</td><td>-0.06</td><td>7.21</td><td>69.50</td><td>195.54</td></tr>\n",
    "<tr><td>11605129</td><td>1.75</td><td>4827.26</td><td>2.50</td><td>0.05</td><td>-0.06</td><td>0.43</td><td>0.05</td><td>4.62</td><td>66.70</td><td>292.26</td></tr>\n",
    "<tr><td>11620695</td><td>1.45</td><td>4773.98</td><td>2.53</td><td>-0.19</td><td>-0.30</td><td>0.09</td><td>-0.20</td><td>4.63</td><td>58.60</td><td>186.93</td></tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "## Misclassified red clump stars\n",
    "<table>\n",
    "<thead><tr><td>KIC</td><td>M</td><td>T_eff</td><td>log(g)</td><td>M_H</td><td>C</td><td>N</td><td>Fe</td><td>Dnu</td><td>PS</td><td>PS Reg.</td></tr></thead>\n",
    "<tr><td>5218333</td><td>1.52</td><td>4664.12</td><td>2.61</td><td>0.09</td><td>0.02</td><td>0.48</td><td>0.09</td><td>5.51</td><td>285.20</td><td>92.43</td></tr>\n",
    "<tr><td>5613570</td><td>1.5</td><td>4596.66</td><td>2.64</td><td>0.31</td><td>0.25</td><td>0.69</td><td>0.31</td><td>5.51</td><td>345.70</td><td>97.82</td></tr>\n",
    "<tr><td>6188215</td><td>2.45</td><td>4983.11</td><td>3.01</td><td>0.07</td><td>-0.23</td><td>0.54</td><td>0.08</td><td>8.73</td><td>164.20</td><td>141.19</td></tr>\n",
    "<tr><td>6528720</td><td>1.51</td><td>4807.08</td><td>2.71</td><td>0.02</td><td>-0.21</td><td>0.43</td><td>0.03</td><td>4.70</td><td>262.20</td><td>134.52</td></tr>\n",
    "<tr><td>6967600</td><td>1.58</td><td>4744.95</td><td>2.76</td><td>0.16</td><td>0.07</td><td>0.57</td><td>0.14</td><td>4.31</td><td>263.70</td><td>184.80</td></tr>\n",
    "<tr><td>10136291</td><td>1.16</td><td>4555.11</td><td>2.42</td><td>-0.18</td><td>-0.13</td><td>-0.00</td><td>-0.18</td><td>4.12</td><td>290.50</td><td>80.58</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity - sampling same parameters but different PS - what changes?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
